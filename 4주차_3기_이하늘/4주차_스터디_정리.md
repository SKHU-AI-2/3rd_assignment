# 딥러닝 기초 요약

## 목차
1. 퍼셉트론
2. 다층 퍼셉트론
3. 활성화 함수
4. 순전파와 역전파

---

## 1. 퍼셉트론
- 인공 신경망의 기본 구성 요소로, 다수의 입력을 받아 하나의 출력(0 또는 1)을 생성.
- **학습 방법**: 좌표평면에 직선을 긋고, 입력값에 따른 모델 예측과 정답을 비교하여 틀린 경우 직선을 수정.
- **한계**: 선형적 데이터만 분류 가능(XOR 문제 등).

## 2. 다층 퍼셉트론
- 입력층과 출력층 사이에 1개 이상의 은닉층이 존재하며, 복잡한 특성 학습 가능.
- 다수의 은닉층을 포함하면 심층 신경망(Deep Neural Network)이 됨.
- **은닉층 역할**: 비선형 데이터를 학습하여 더 정교한 모델 생성 가능.

## 3. 활성화 함수
- 입력값의 총합을 출력할지 결정하고, 특정 값으로 변환하여 출력.
    - **계단 함수**: 입력의 총합이 0보다 작으면 -1, 0보다 크면 1 출력.
    - **시그모이드 함수**: 출력값이 0~1 사이로 확률 표현 가능하지만, 큰 입력값에서 기울기 소실 문제 발생.
- **비선형 함수의 중요성**: 선형 함수 사용 시 신경망의 깊이를 늘려도 큰 효과를 보기 어려움.

## 4. 순전파와 역전파
### 순전파
- 입력 데이터가 신경망의 각 층을 순차적으로 통과하여 최종 출력 생성.
    - **과정**: 가중합 계산 → 활성화 함수 적용(예: 시그모이드) → 최종 출력값 생성.
    - **손실 함수**: 평균 제곱 오차(MSE) 사용하여 오차 계산.

### 역전파
- 예측값과 실제값의 차이를 줄이기 위한 학습 과정.
    - **과정**: 오차 함수의 가중치에 대한 미분을 계산하여 가중치 업데이트.
    - **연쇄법칙 사용**: 시그모이드 함수의 미분(f(x) * (1 - f(x))) 이용.
    - **학습률 설정**: 학습률(예: 0.5)을 바탕으로 가중치 조정.

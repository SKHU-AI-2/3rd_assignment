퍼셉트론 – 인공신경망 구성요소, 다수 입력값 -> 하나의 출력(0 or 1)
=============================================================
가중치가 클수록 입력값이 중요
입력 – 가중치 – 활성화 함수 – 출력값
활성화 함수 -> 입력값의 총합의 출력 결정

퍼셉트론 학습방법
----------------
1. 좌표평면 임의의 직선을 기준으로 데이터 하나씩 입력
2. 입력값에 따른 모델의 예측값과 정답 비교 후 틀린 경우 직선 다시 긋기
3. 모든 학습용 데이터에 대해 2,3 과정 반복

퍼셉트론의 한계
--------------
데이터가 선형적으로 구분 가능해야만 문제 해결
XOR문제를 통한 한계 증명 (XOR -> 두 입력 값이 서로 달라야 1)

다층 퍼셉트론
--------------
입력층-출력측 사이 1개 이상 은닉층 존재 -> 이 경우 다층 퍼셉트론
2개 이상 은닉층 가짐 -> 심층신경망
은닉층이 많을수록 정확도가 올라가되 정확성는 보장하지 않는다.

활성화 함수
--------------
퍼셉트론에서 입력값의 총합 출력 결정, 출력 시 어떤 값으로 변환하여 출력할지 결정함
-	계단함수 -> 입력값 총합 < 0 => -1 출력 / 반대 경우 1출력
-	단순 데이터 분리 여부에 초점, 세심한 분리 X

시그모이드 함수
--------------
- 값이 작아질수록 0, 커질수록 1수렴
- 출력이 0, 1 사이로 확률 표현
- 입력값 크더라도 출력 값의 범위와 0과 1사이로 매우 좁음
- 경사하강법 수행시 범위가 좁음 관계로 0애 수렴하는 기울기 소실 문제 발생

비선형 함수 사용 이유
---------------------
- 선형 함수 자체가 심층 신경망에 큰 효과적인 도움 X
- 단 하나의 층으로 표현할 수 있게 되면서 신경망을 깊게 쌓는 의미 희석


순전파
------
- 신경망에서 입력데이터가 네트워크의 각 층을 순차적 통과 후, 최종출력 생성 과정
- 오차 계산하기 위한 손실함수로는 평균 제곱 오차 MSE 사용

역전파
------
- 예측값과 실제값의 차이를 줄이기 위한 과정
- 오차를 기반으로 가중치 값들을 업데이트 하기 위해 역행함
- 오차함수를 가중치로 미분 -> 오차가 가중치에 따라 민감한 변화 측정.

..
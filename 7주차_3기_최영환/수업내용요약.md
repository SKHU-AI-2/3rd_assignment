### Object Detection
1. **Object Detection**:
    - 이미지에서 객체를 찾고, 그 위치와 클래스 라벨을 예측
    - 주요 평가 지표: **IOU(Intersection over Union)**
    - 겹치는 영역(실제 이미지에서 라벨링한 영역과 예측한 area) / 전체 영역(겹치는 영역을 포함한 모든 area)

2. **Object Detection 방법**:
    - **R-CNN**:
        1. Input Image
        2. RoI(Region of Interest) 선택 (Selective Search 사용)
        3. RoI를 동일한 크기로 Resizing
        4. ConvNet 통과 (특징 추출)
        5. SVM으로 분류 및 Bounding Box 위치 조정
    - **Fast R-CNN**:
        1. ConvNet으로 Feature Map 생성
        2. RoI(Region of Interest)를 특징 맵에 적용
        3. Fully Connected Layer(FC) 통과 후 클래스 및 Bounding Box 좌표 예측
    - **YOLO(You Only Look Once)**:
        - 이미지 전체를 한 번에 ConvNet에 입력
        - Bounding Box, 클래스 확률, 신뢰도를 동시에 출력

### Image Segmentation
1. **Semantic Segmentation**:
    - 각 픽셀을 특정 클래스(예: 사람, 고양이, 하늘 등)로 분류
    - 물체의 실루엣 추출

2. **Instance Segmentation**:
    - 각 객체로 구분
    - **Mask R-CNN**:
        1. Input Image
        2. CNN을 통한 Feature Map 생성
        3. Region Proposal Network(RPN)으로 객체 후보 영역 생성
        4. RoI Pooling
        5. 물체 클래스, Bounding Box, 픽셀 단위 마스크 출력

### Pose Estimation
1. 관절 위치를 픽셀 단위로 예측
2. Heatmap 생성하여 관절 위치 가능성 시각화
3. 각 관절 정보를 결합해 정확한 위치 추출
4. **open source Library**:
    - OpenPose
    - MediaPipe
    - DensePose

### Vision Transformer (ViT)
1. Input Image를 작은 패치로 분할
2. 각 패치를 선형 변환 후 위치 정보와 Token 부여
3. Transformer Encoder 통과
4. Class Token을 통해 최종 클래스 예측

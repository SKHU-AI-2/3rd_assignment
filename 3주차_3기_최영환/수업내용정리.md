## 비지도 학습과 준지도 학습 개요
---

### 1. Gradient Descent (경사하강법)
 - **기본 개념**: 손실 함수의 기울기를 이용해 손실함수가 최소가 되는 지점을 찾는다.

 - **업데이트**

$$
\begin{aligned}
\hat{y} &= w \cdot x + b \\
w &= w - lr \nabla J(w)
\end{aligned}
$$

 - **하이퍼 파라미터**:
    - **학습률 (Learning Rate)**: 가중치를 업데이트할 때 기울기를 얼마나 반영할지 설정
    - **반복 횟수 (Epoch)**: 얼마나 업데이트를 반복할 지 설정

 - **한계점**:
    - **Local Minimum**: 손실 함수의 여러 최저점 중 지역 최저점에 도달할 수 있음
    - **Feature Scaling**: 데이터 스케일의 영향을 받음
    - **Learning Rate**: 학습률을 너무 높게 하면 최저점을 지나쳐 수렴하지 않고, 너무 낮으면 학습 속도가 느려짐
    - **미분 가능성**: 미분가능 해야 학습에 적용 할 수 있음

### 2. 비지도 학습 (Unsupervised Learning)
- **기본 개념**: 레이블이 없는 데이터에서 패턴을 찾는 방법

- **주요 기법**:
    - **군집화 (Clustering)**: 데이터의 유사성을 바탕으로 그룹화, K-means, DBSCAN, Mean-Shift
    - **특이치 탐지 (Anomaly Detection)**: 사기 탐지 , 제조 공정 이상탐지 등에서 사용됨
    - **생성형 작업 (Generative Tasks)**: GAN, VAE 등이 대표적이며, 데이터의 분포를 학습해 이미지나 텍스트를 생성
    - **차원 축소**: 고차원 데이터를 저차원으로 변환하여 차원의 저주를 일부 해결 하지만, 일부 정보가 손실

- **DBSCAN**: 밀도 기반 클러스터링, 뭉쳐있으면 같은 데이터로 인식, feature가 많아지면 분류능력이 떨어짐
- **Isolate Forest**: 모든 포인트가 고립될 때까지 tree를 만듦. 빨리 고립되는 포인트가 특이치
    - 큰 data set에 잘 작동
    - 고차원 데이터의 특이치를 효과적으로 탐지

### 3. 준지도 학습 (Semi-supervised Learning)
- **정의**: 일부 라벨 데이터와 비라벨 데이터를 함께 사용해 학습. 주로 분류에 사용

- **가정**:
    - **Smoothness Assumption**: 가까운 데이터 포인트는 유사한 출력을 가집니다.
    - **Cluster Assumption**: 같은 군집의 데이터는 같은 클래스로 분류될 가능성이 큽니다.

- **방법론**:
    - **Proxy Label Method**: 라벨 데이터로 모델을 학습하고, 비라벨 데이터에 pseudo-label을 적용해 다시 학습에 반영. pseudo-labeled data는 주로 신뢰도가 높은 데이터만 사용(결정 경계에서 멀수록 신뢰도가 높음)
    - **Consistency Training**: 데이터에 변화를 가한 후에도 예측 결과가 동일하도록 학습